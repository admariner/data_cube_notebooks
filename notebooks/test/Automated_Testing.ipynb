{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from nbconvert.preprocessors import CellExecutionError\n",
    "from nbclient.exceptions import CellControlSignal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of notebooks to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.environ.get('NOTEBOOK_ROOT'))\n",
    "\n",
    "# exclude 'machine_learning' because we do not have the data \n",
    "#   to test the Uruguay Random Forest notebooks.\n",
    "# exclude 'UN_SDG_15_3_1.ipynb' due to no land change data (instructions in nbk).\n",
    "# exclude 'ALOS_Land_Change.ipynb' due to no ALOS data.\n",
    "# exclude 'Landslide_Identification_SLIP.iypnb' due to no TERRA ASTER data.\n",
    "# exclude 'Forest_Change_VNSC.ipynb' due to no TERRA ASTER data.\n",
    "# exclude 'Shallow_Water_Bathymetry.ipynb' due to no Landsat 8 Level 1 data.\n",
    "# exclude 'ALOS_WASARD.ipynb' due to no ALOS data.\n",
    "# exclude 'water_interoperability_similarity.ipynb' due to no Sentinel-2 data.\n",
    "exclude_subpaths = ['.ipynb_checkpoints', 'experimental', 'IGARSS', \n",
    "                    'legacy', 'machine_learning', 'test', 'utils',  \n",
    "                    'Automated_Testing.ipynb', 'UN_SDG_15_3_1.ipynb',\n",
    "                    'ALOS_Land_Change.ipynb', 'Landslide_Identification_SLIP.ipynb',\n",
    "                    'Forest_Change_VNSC.ipynb', 'Shallow_Water_Bathymetry.ipynb',\n",
    "                    'ALOS_WASARD.ipynb', 'water_interoperability_similarity.ipynb',\n",
    "                    ]\n",
    "notebook_file_paths = []\n",
    "for root, directories, files in os.walk('..', topdown=True):\n",
    "    notebook_file_paths.extend([os.path.join(root, file) for file in files if file.endswith('.ipynb')])\n",
    "notebook_file_paths = sorted(notebook_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out notebooks using `exclude_subpaths`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_filepath_excluded(filepath, exclude_subpaths):\n",
    "    return any(list(map(lambda subpath: subpath in filepath, exclude_subpaths)))\n",
    "notebook_file_paths = [filepath for filepath in notebook_file_paths if not is_filepath_excluded(filepath, exclude_subpaths)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the notebooks and record their status (e.g. working, error) to HTML as each completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ../DCAL/DCAL_Cloud_Statistics.ipynb\n",
      "Running ../DCAL/DCAL_Custom_Mosaics.ipynb\n",
      "Running ../DCAL/DCAL_Custom_Mosaics_Dask.ipynb\n",
      "Running ../DCAL/DCAL_Land_Change.ipynb\n",
      "Running ../DCAL/DCAL_Spectral_Products.ipynb\n",
      "Running ../DCAL/DCAL_Vegetation_Phenology.ipynb\n",
      "Running ../DCAL/DCAL_Water_Extents.ipynb\n",
      "Running ../DCAL/DCAL_Water_WOFS.ipynb\n",
      "Running ../DEM/SRTM_Product_Showcase_v2.ipynb\n",
      "Running ../SAR/Sentinel1_Viewer.ipynb\n",
      "Running ../UN_SDG/UN_SDG_11_3_1.ipynb\n",
      "Running ../UN_SDG/UN_SDG_6_6_1.ipynb\n",
      "Running ../animation/2D/GIF_Notebook.ipynb\n",
      "Running ../animation/3D/GA_Water_3D_Reservoir/GA_Water_3DReservoir.ipynb\n",
      "Running ../compositing/Composites.ipynb\n",
      "Running ../compositing/Geomedians_and_Geomedoids.ipynb\n",
      "Running ../feature_extraction/Clustering_Notebook.ipynb\n",
      "Running ../general/Export.ipynb\n",
      "Running ../general/Notebook_Template.ipynb\n",
      "Running ../general/Shapefile_Masking.ipynb\n",
      "Running ../scalability/Dask/Dask_Tutorial_Notebook.ipynb\n",
      "Running ../training/ardc_training/Training_TaskA_Mosaics.ipynb\n",
      "Running ../training/ardc_training/Training_TaskB_Water.ipynb\n",
      "Running ../training/ardc_training/Training_TaskC_Indices.ipynb\n",
      "Running ../training/ardc_training/Training_TaskD_LandChange.ipynb\n",
      "Running ../training/ardc_training/Training_TaskE_Transect.ipynb\n",
      "Running ../training/ardc_training/Training_TaskF_DataExport.ipynb\n",
      "Running ../urbanization/Urbanization_Using_NDBI.ipynb\n",
      "Running ../vegetation/NDVI_Anomaly.ipynb\n",
      "Running ../vegetation/NDVI_STD.ipynb\n",
      "Running ../vegetation/NDVI_Thresholds.ipynb\n",
      "Running ../vegetation/Vegetation_Change_S2.ipynb\n",
      "Running ../vegetation/forests/Forest_Degradation_Vogelmann_et_al.ipynb\n",
      "Running ../vegetation/forests/deutscher_SAR_deforestation.ipynb\n",
      "Running ../vegetation/phenology/Vegetation_Phenology.ipynb\n",
      "Running ../water/coastline/Coastal_Change_Classifier.ipynb\n",
      "Running ../water/coastline/Coastline_Classifier.ipynb\n",
      "Running ../water/detection/SAR/Sentinel1_WASARD.ipynb\n",
      "Running ../water/detection/water_detection_with_wofs.ipynb\n",
      "Running ../water/quality/TSM_Demo.ipynb\n",
      "Running ../water/quality/TSM_Demo_Dask.ipynb\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas\n",
    "ansi_escape = re.compile(r'\\x1B(?:[@-Z\\\\-_]|\\[[0-?]*[ -/]*[@-~])')\n",
    "full_report = pandas.DataFrame(columns=['Notebook', 'Status', 'Bug Description'])\n",
    "error_report = pandas.DataFrame(columns=['Notebook', 'Status', 'Bug Description'])\n",
    "success_report = pandas.DataFrame(columns=['Notebook', 'Status', 'Bug Description'])\n",
    "for notebook_file_path in notebook_file_paths:\n",
    "    print(f'Running {notebook_file_path}')\n",
    "    run_result = {'Notebook': notebook_file_path, 'Status': 'Working', 'Bug Description': ''}\n",
    "    with open(notebook_file_path, 'r+', encoding='utf-8') as notebook_file:\n",
    "        notebook = nbformat.read(notebook_file, as_version=4)\n",
    "        notebook_runner = ExecutePreprocessor(timeout=None)\n",
    "        try:\n",
    "            notebook_runner.preprocess(notebook, {'metadata': {'path': os.path.dirname(notebook_file_path)}})\n",
    "        except CellExecutionError as err:\n",
    "            run_result['Status'] = 'Error'\n",
    "            run_result['Bug Description'] = err\n",
    "        nbformat.write(notebook, notebook_file_path)\n",
    "    full_report = full_report.append(run_result, ignore_index=True)\n",
    "    if run_result['Status'] == 'Error':\n",
    "        error_report = error_report.append(run_result, ignore_index=True)\n",
    "    else:\n",
    "        success_report = success_report.append(run_result, ignore_index=True)\n",
    "    full_report.to_html('full_test_report.html', escape=False, formatters={'Bug Description': lambda e: ansi_escape.sub('', str(e).replace('\\n', '<br/>'))})\n",
    "    error_report.to_html('error_report.html', escape=False, formatters={'Bug Description': lambda e: ansi_escape.sub('', str(e).replace('\\n', '<br/>'))})\n",
    "    success_report.to_html('success_report.html', escape=False, formatters={'Bug Description': lambda e: ansi_escape.sub('', str(e).replace('\\n', '<br/>'))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the results to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_report['Bug Description'] = full_report['Bug Description'].map(lambda e: ansi_escape.sub('', str(e)))\n",
    "full_report.to_csv('full_test_report.csv')\n",
    "error_report['Bug Description'] = error_report['Bug Description'].map(lambda e: ansi_escape.sub('', str(e)))\n",
    "error_report.to_csv('error_report.csv')\n",
    "success_report['Bug Description'] = success_report['Bug Description'].map(lambda e: ansi_escape.sub('', str(e)))\n",
    "success_report.to_csv('success_report_report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Vegetation Change\n",
    "\n",
    "This notebook uses changes in the Normalized Difference Vegetation Index (NDVI) to identify vegetation change. The algorithm identifies a \"baseline\" and \"analysis\" time period and then compares the spectral index in each of those time periods. Significant changes in NDVI (vegetation greenness) are coincident with land change, as long as the comparisons are done between similar time periods (seasons or years). Users of this algorithm should not accept the accuracy of the results but should conduct ground validation testing to assess accuracy. It is expected that this algorithm can be used to identify clusters of pixels that have experienced change and allow targeted investigation of those areas by local or regional governments. In some cases the impacts may be negative (deforestation, mining, burning, drought) or positive (regrowth, improved soil moisture). \n",
    "\n",
    "It should also be noted that the selection of the baseline and analysis time period is critical. First, the two time periods should be similar (season, year) so that the vegetation state can be compared in similar weather conditions. Second, the time periods should be sufficient clear (non-cloudy) data. If the baseline or analysis mosaic (composite of images) is contaminated with clouds, it will impact the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"connect_dc\">Connect to the Data Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.environ.get('NOTEBOOK_ROOT'))\n",
    "\n",
    "import warnings\n",
    "# Supress Warning \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datacube.utils.aws import configure_s3_access\n",
    "configure_s3_access(requester_pays=True)\n",
    "\n",
    "import utils.data_cube_utilities.data_access_api as dc_api  \n",
    "api = dc_api.DataAccessApi()\n",
    "dc = api.dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"plat_prod\">Choose Platforms and Products [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a Product and Platform\n",
    "product = 's2_google_vanuatu'\n",
    "platform = 'SENTINEL-2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"extents\">Get the Extents of the Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print extents of the data cube\n",
    "extents = api.get_full_dataset_extent(platform = platform, product = product)\n",
    "latitude_extents = (min(extents['latitude'].values),max(extents['latitude'].values))\n",
    "longitude_extents = (min(extents['longitude'].values),max(extents['longitude'].values))\n",
    "time_extents = (min(extents['time'].values),max(extents['time'].values))\n",
    "print(time_extents)\n",
    "print(latitude_extents)\n",
    "print(longitude_extents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"define_extents\">Define the Extents of the Analysis [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an analysis region \n",
    "\n",
    "# Vanuatu - Peninsula near Port Vila \n",
    "latitude = (-17.75, -17.63) \n",
    "longitude = (168.15, 168.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The code below renders a map that can be used to orient yourself with the region.\n",
    "from utils.data_cube_utilities.dc_display_map import display_map\n",
    "display_map(latitude = latitude, longitude = longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"define_analysis_params\">Define Analysis Parameters [&#9652;](#top)</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Select the start and end periods for your analysis products\n",
    "# The datetime function is (Year,Month,Day)\n",
    "# These time windows will be used to make a mosaic, so typically pick a year length (or more)\n",
    "# or select a small window surrounding a clear single date (use Cloud Statistics notebook)\n",
    "# Also, be sure to evaluate the RGB mosaics (below) to affirm they are not full of clouds\n",
    "\n",
    "# Select the baseline time period (start and end)\n",
    "baseline_time_period = (datetime(2019,7,27), datetime(2019,7,29))\n",
    "\n",
    "# Select the analysis time period (start and end)\n",
    "analysis_time_period = (datetime(2020,7,1), datetime(2020,7,3))\n",
    "\n",
    "# Select the cloud-free mosaic type\n",
    "# Options are: max_ndvi, median, most_recent_pixel\n",
    "# Use \"median\" for longer time periods, such as a year\n",
    "# Use \"most_recent_pixel\" for short time periods, such as one day\n",
    "# Use \"max_ndvi\" for seasonal time periods to compare vegetation peaks\n",
    "\n",
    "baseline_mosaic_function = \"most_recent_pixel\" \n",
    "analysis_mosaic_function = \"most_recent_pixel\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"load_data\">Load and Clean Data from the Data Cube [&#9652;](#top)</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_load_params = \\\n",
    "    dict(latitude=latitude,longitude=longitude,platform=platform,product=product,\n",
    "         measurements = ['red', 'green', 'blue', 'nir', 'swir1', 'swir2', 'scl'],\n",
    "         group_by='solar_day', dask_chunks={'time':1, 'latitude':1000, 'longitude':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_ds = dc.load(**common_load_params,\n",
    "                      time=baseline_time_period) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_ds = dc.load(**common_load_params,\n",
    "                      time=analysis_time_period) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_mask_baseline = (baseline_ds.scl != 0) & (baseline_ds.scl != 1) & \\\n",
    "                      (baseline_ds.scl != 3) & (baseline_ds.scl != 8) & \\\n",
    "                      (baseline_ds.scl != 9) & (baseline_ds.scl != 10)\n",
    "baseline_ds = baseline_ds.where(cloud_mask_baseline)\n",
    "\n",
    "cloud_mask_analysis = (analysis_ds.scl != 0) & (analysis_ds.scl != 1) & \\\n",
    "                      (analysis_ds.scl != 3) & (analysis_ds.scl != 8) & \\\n",
    "                      (analysis_ds.scl != 9) & (analysis_ds.scl != 10)\n",
    "analysis_ds = analysis_ds.where(cloud_mask_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Mosaic for the Baseline and Analysis Time Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_special.data_cube_utilities.dc_mosaic import create_max_ndvi_mosaic, create_median_mosaic, create_mosaic\n",
    "mosaic_function = {\"median\": create_median_mosaic,\n",
    "                   \"max_ndvi\": create_max_ndvi_mosaic,\n",
    "                   \"most_recent_pixel\": create_mosaic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_compositor = mosaic_function[baseline_mosaic_function]\n",
    "analysis_compositor = mosaic_function[analysis_mosaic_function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_composite = baseline_compositor(baseline_ds, cloud_mask_baseline.values)\n",
    "analysis_composite = analysis_compositor(analysis_ds, cloud_mask_analysis.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"anomalies\">Calculate Anomaly Product [&#9652;](#top)</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDVI(dataset):\n",
    "    return (dataset.nir - dataset.red)/(dataset.nir + dataset.red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_baseline_composite = NDVI(baseline_composite)\n",
    "parameter_analysis_composite = NDVI(analysis_composite)\n",
    "parameter_anomaly = parameter_analysis_composite - parameter_baseline_composite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Baseline RGB, Analysis RGB and Anomaly Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils.data_cube_utilities.dc_rgb import rgb\n",
    "from matplotlib.cm import RdYlGn\n",
    "RdYlGn.set_bad('black',1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the significant anomaly range for Plot #4\n",
    "loss_range  = parameter_anomaly < -0.2\n",
    "gain_range  = parameter_anomaly > 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12,12))\n",
    "\n",
    "for sub_ax in ax.flatten():\n",
    "    sub_ax.set_facecolor('black')\n",
    "\n",
    "baseline_rgb = baseline_composite[['red', 'green', 'blue']].to_array()\n",
    "analysis_rgb = analysis_composite[['red', 'green', 'blue']].to_array()\n",
    "\n",
    "# Use the middle values of the data (2% to 98%) to brighten the image\n",
    "lw_qtl, up_qtl = 0.02, 0.98\n",
    "rgb_vmin = min(baseline_rgb.quantile(lw_qtl).values,analysis_rgb.quantile(lw_qtl).values)\n",
    "rgb_vmax = max(baseline_rgb.quantile(up_qtl).values,analysis_rgb.quantile(up_qtl).values)\n",
    "\n",
    "# Plot the resulting 4 products ... Baseline RGB, Analysis RGB, Total Anomaly, Anomaly Threshold\n",
    "# NOTE: Clouds in either the baseline or analysis images will be removed from the anomaly product\n",
    "\n",
    "## Plot #1 = Baseline RGB (upper left)\n",
    "axes_image = baseline_rgb.plot.imshow(ax=ax[0,0], vmin=rgb_vmin, vmax=rgb_vmax)\n",
    "\n",
    "## Plot #2 = Analysis RGB (upper right)\n",
    "analysis_rgb.plot.imshow(ax=ax[0,1], vmin=rgb_vmin, vmax=rgb_vmax)\n",
    "\n",
    "## Plot #3 = Total Anomaly (lower left)\n",
    "parameter_anomaly.plot(ax=ax[1,0], vmin=-0.4, vmax=0.4, cmap = RdYlGn, add_colorbar=False)\n",
    "\n",
    "## Plot #4 = Anomaly Threshold (lower right)\n",
    "\n",
    "# Analysis composite grayscale background\n",
    "plt4_bkg_band = 'swir1' # The band to use as the background image.\n",
    "plt4_rgb = np.repeat(analysis_composite[plt4_bkg_band].where(cloud_mask_baseline.squeeze('time'))\\\n",
    "                     .values[:,:,np.newaxis],3,axis=2)\n",
    "\n",
    "# Selected a range of SWIR1 values (0.001 to 0.600) to lighten image background (vs. 0.02 and 0.98)\n",
    "min_bkg = np.nanquantile(analysis_composite[plt4_bkg_band].values, 0.001)\n",
    "max_bkg = np.nanquantile(analysis_composite[plt4_bkg_band].values, 0.600)\n",
    "plt4_rgb = np.interp(plt4_rgb, (min_bkg, max_bkg), [0,1])\n",
    "\n",
    "# Significant anomaly color overlays\n",
    "color_green = np.array([0,1,0]) # green\n",
    "color_red   = np.array([1,0,0]) # red\n",
    "plt4_rgb[loss_range] = color_red\n",
    "plt4_rgb[gain_range] = color_green\n",
    "\n",
    "# Plot\n",
    "plt4_coords = dict(analysis_composite.coords)\n",
    "rgb_coord_arr = np.array(['red', 'green', 'blue'])\n",
    "rgb_coord_da = xr.DataArray(rgb_coord_arr,name='rgb',dims=['rgb'],coords={'rgb': rgb_coord_arr})\n",
    "plt4_coords.update({'rgb': rgb_coord_da})\n",
    "plt4_rgb_da = xr.DataArray(plt4_rgb, coords=plt4_coords,dims=list(analysis_composite.dims) + ['rgb'])\n",
    "plt4_rgb_da.plot.imshow(ax=ax[1,1])\n",
    "\n",
    "# Titles for all plots\n",
    "ax[0,0].set_title('Baseline Composite'), ax[0,0].xaxis.set_visible(False), ax[0,0].yaxis.set_visible(False)\n",
    "ax[0,1].set_title('Analysis Composite'), ax[0,1].xaxis.set_visible(False), ax[0,1].yaxis.set_visible(False)\n",
    "ax[1,0].set_title('Vegetation Anomalies: Red=Loss, Green=Gain'), ax[1,0].xaxis.set_visible(False), ax[1,0].yaxis.set_visible(False)\n",
    "ax[1,1].set_title('Locations of Significant Anomalies: Red=Loss, Green=Gain'), ax[1,1].xaxis.set_visible(False), ax[1,1].yaxis.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Pixel Counts within Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_count(da, min_threshold, max_threshold, mask = None):\n",
    "    def count_not_nans(arr):\n",
    "        return np.count_nonzero(~np.isnan(arr))\n",
    "    \n",
    "    in_threshold = np.logical_and( da.values > min_threshold, da.values < max_threshold)\n",
    "    \n",
    "    total_non_cloudy = count_not_nans(da.values) if mask is None else np.sum(mask) \n",
    "    \n",
    "    return dict(total = np.size(da.values),\n",
    "                total_non_cloudy = total_non_cloudy,\n",
    "                inside = np.nansum(in_threshold),\n",
    "                outside = total_non_cloudy - np.nansum(in_threshold)\n",
    "               )    \n",
    "    \n",
    "def threshold_percentage(da, min_threshold, max_threshold, mask = None):\n",
    "    counts = threshold_count(da, min_threshold, max_threshold, mask = mask)\n",
    "    return dict(percent_inside_threshold = (counts[\"inside\"]   / counts[\"total\"]) * 100.0,\n",
    "                percent_outside_threshold = (counts[\"outside\"] / counts[\"total\"]) * 100.0,\n",
    "                percent_clouds = ( 100.0-counts[\"total_non_cloudy\"] / counts[\"total\"] * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an Anomaly Threshold Range to calculate the results from the previous image\n",
    "# Be sure to put the smallest value in the \"minimum_change\" location (be careful of negative values)\n",
    "# This code block can be used for either vegetation loss or vegetation gain calculations\n",
    "\n",
    "# NDVI losses might use the following limits: min=-1.0 and max=-0.2\n",
    "# NDVI gains might use the following limits: min=0.2, max=1.0\n",
    "\n",
    "minimum_change = -0.7\n",
    "maximum_change = -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This output is a count of the pixels that fall within each threshold range\n",
    "\n",
    "threshold_count(parameter_anomaly,minimum_change,maximum_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This output is a percentage of the pixels that fall within each threshold range\n",
    "\n",
    "threshold_percentage(parameter_anomaly,minimum_change,maximum_change)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
